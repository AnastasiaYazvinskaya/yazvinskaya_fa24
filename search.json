[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Final project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\nMarkDown Basics"
  },
  {
    "objectID": "index.html#project0---introduction",
    "href": "index.html#project0---introduction",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Final project"
  },
  {
    "objectID": "index.html#project1---whats-in-a-name",
    "href": "index.html#project1---whats-in-a-name",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project2---late-flights-and-missing-data-json",
    "href": "index.html#project2---late-flights-and-missing-data-json",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project3---finding-relationships-in-baseball",
    "href": "index.html#project3---finding-relationships-in-baseball",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project4---can-you-predict-that",
    "href": "index.html#project4---can-you-predict-that",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project5---the-war-with-star-wars",
    "href": "index.html#project5---the-war-with-star-wars",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project6---git-your-portfolio-online",
    "href": "index.html#project6---git-your-portfolio-online",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project\n\nMarkDown Basics"
  },
  {
    "objectID": "Templates/DS250_Template.html",
    "href": "Templates/DS250_Template.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "THIS .qmd IS INSTRUCTIONAL AND SHOULD NOT BE USED TO WRITE YOUR REPORTS (EXCEPTION - PROJECT 0). THERE IS ANOTHER TEMPLATE FILE FOR THAT. YOU WILL NEED TO PREVIEW THE REPORT TO PRODUCE A .html FILE. YOU WILL SUBMIT THE .html FILE ON CANVAS."
  },
  {
    "objectID": "Templates/DS250_Template.html#elevator-pitch",
    "href": "Templates/DS250_Template.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nA SHORT (2-3 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS. (Note: this is not a summary of the project, but a summary of the results.)\nA Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/mpg/mpg.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-1",
    "href": "Templates/DS250_Template.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 1",
    "text": "Question|Task 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\nAdd details here to answer the question but NOT like an assignment Q&A. You need to write your answers as a consulting solution report. A Client needs to understand the answer, but also needs to understand the decisions that went into the answer (when applicable).\ninclude figures in chunks and discuss your findings in the figure.\n\nYOU SHOULD HAVE QUALITY WRITING THAT DESCRIBES YOUR CHARTS AND TABLES.\nWE HIGHLY RECOMMEND GRAMMARLY TO FIX YOUR SPELLING AND GRAMMAR. WRITING TAKES TIME TO BE CLEAR. SPEND THE TIME TO PRACITCE.\nYOU SHOULD HAVE QUALITY COMMENTS THAT DESCRIBES YOUR CODES. OFTEN CODEERS WORK IN TEAMS AND YOU NEED TO HAVE QUALTIY COMMENTS FOR YOUR TEAM AND YOURSELF. YOU MAY NEED TO REVISIT CODE YOU WROTE OVER A YEAR AGO, AND IF YOU DONT COMMENT IT NOW YOU WONT REMEMBER WHY YOU DID WHAT YOU DID.\n\n\n\nRead and format data\n# Include and execute your code here"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-2",
    "href": "Templates/DS250_Template.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 2",
    "text": "Question|Task 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\n\nplot example\n# Include and execute your code here\n\n(\n  ggplot(df.head(500), aes(x='displ', y='hwy')) + geom_point()\n)\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nMy useless chart"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-3",
    "href": "Templates/DS250_Template.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 3",
    "text": "Question|Task 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\n\nPROVIDE TABLES THAT HELP ADDRESS THE QUESTIONS AND TASKS (IF APPLICABLE).\n\n\n\ntable example\n# Include and execute your code here\nmydat = (df.head(1000)\n    .groupby('manufacturer')\n    .sum()\n    .reset_index()\n    .tail(10)\n    .filter([\"manufacturer\",\"displ\",\"cty\", \"hwy\"])\n)\n\ndisplay(mydat)\n\n\n\n\n\n\ntable example {#cell-Q1-table}\n\n\n\nmanufacturer\ndispl\ncty\nhwy\n\n\n\n\n5\nhyundai\n34.0\n261\n376\n\n\n6\njeep\n36.6\n108\n141\n\n\n7\nland rover\n17.2\n46\n66\n\n\n8\nlincoln\n16.2\n34\n51\n\n\n9\nmercury\n17.6\n53\n72\n\n\n10\nnissan\n42.5\n235\n320\n\n\n11\npontiac\n19.8\n85\n132\n\n\n12\nsubaru\n34.4\n270\n358\n\n\n13\ntoyota\n100.4\n630\n847\n\n\n14\nvolkswagen\n60.9\n565\n789\n\n\n\n\n\n\n\nNote: Non executing Python Snippets include (3) ``` followed by (3) more ```, each on their own line. These are not single quotes, they are the key left of the number 1 key on the keyboard. The top row can include the language of code that is pasted inbetween the ``` marks.\nNote: These also work in Slack and it is expected they are used for any code shared in that app. No screen shots allowed."
  },
  {
    "objectID": "250_Projects/project1.html",
    "href": "250_Projects/project1.html",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "Through this project I had the opportunity to become more familiar with working with graphs when searching for specific information. It was very interesting for me to study the history of the use of various names, since it gives us an understanding of how many people with a specific name were born in certain years and how old they might be now. In the example with question 2 about the name Brittany, I was interested in how much our association with name and age coincides with reality.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_names = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#elevator-pitch",
    "href": "250_Projects/project1.html#elevator-pitch",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "Through this project I had the opportunity to become more familiar with working with graphs when searching for specific information. It was very interesting for me to study the history of the use of various names, since it gives us an understanding of how many people with a specific name were born in certain years and how old they might be now. In the example with question 2 about the name Brittany, I was interested in how much our association with name and age coincides with reality.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_names = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq1-comparing-name-anastasia-popularity-over-time",
    "href": "250_Projects/project1.html#cq1-comparing-name-anastasia-popularity-over-time",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ1: Comparing Name Anastasia Popularity Over Time",
    "text": "CQ1: Comparing Name Anastasia Popularity Over Time\nHow does your name at your birth year compare to its use historically?\nUntil the 1980s, the popularity of this name was 0-200 children per year, which is quite small, considering that most of the time this figure was below 100. Since the 1980s, active use of this name began. In less than 10 years, its popularity has quadrupled. By the year of my birth (1998), almost 1.5 times. At the moment, this indicator continues to grow.\n\n\nCode - Filter data by name Anastasia and draw a graph with point birth year (1998)\n# Filter data by name\nd_name = df_names.query('name == \"Anastasia\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  geom_vline(xintercept=1998, linetype='dashed', color='green', size=1) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Anastasia') + \\\n  labs(x='Year', y='People born with the name Anastasia')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Anastasia before, on and after 1998",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq2-age-estimation-based-on-name-britany",
    "href": "250_Projects/project1.html#cq2-age-estimation-based-on-name-britany",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ2: Age Estimation Based on Name Britany",
    "text": "CQ2: Age Estimation Based on Name Britany\nIf you talked to someone named Brittany on the phone, what is your guess of their age? What ages would you not guess?\nFor me, the name Brittany is associated with a young woman of about 20. I definitely would not have guessed that she could be 45 or older if the voice itself did not indicate otherwise. However, according to available data, most people with this name are 33-34 years old today.\n\n\nCode - Filter data by name Brittany and draw a graph\n# Filter data by name\nd_name = df_names.query('name == \"Brittany\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Brittany') + \\\n  labs(x='Year', y='People born with the name Brittany')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Brittany",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq3-comparative-analysis-of-christian-names-from-1920-to-2000",
    "href": "250_Projects/project1.html#cq3-comparative-analysis-of-christian-names-from-1920-to-2000",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ3: Comparative Analysis of Christian Names from 1920 to 2000",
    "text": "CQ3: Comparative Analysis of Christian Names from 1920 to 2000\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names.\nPrior to 1970, the most popular name was Mary. It was given to their children 2-4 times more often than the name Paul, which is in second place. An interesting point is that from 1970 to 2000 the use of the names Mary and Paul is almost the same. Martha and Peter are quite rare names for those years from 19021 to 2000. However, it is interesting to note that initially the name Martha was preferable, but after 1950 the situation changed, so that the name Peter became more popular. By 2000, the general usage of all four names was nearly the same.\n\n\nCode - Filter data by Christian names and year (1920-2000) and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name in [\"Mary\", \"Martha\", \"Peter\", \"Paul\"] & year &gt;=1920 & year &lt;=2000')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(aes(color='name'), size=1) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the Christian names') + \\\n  labs(\n    x='Year',\n    y='People born with the Christian names',\n    color='Christian names')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the names between 1920 and 2000 years",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq4-impact-of-a-famous-movie-on-name-usage",
    "href": "250_Projects/project1.html#cq4-impact-of-a-famous-movie-on-name-usage",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ4: Impact of a Famous Movie on Name Usage",
    "text": "CQ4: Impact of a Famous Movie on Name Usage\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI analyzed data on the name Dominic from the movie “Fast and the Furious”. According to the data, before the release of the first film in 2001 year, the name was already growing in popularity. After the first film, we see an increase in the use of this name. However, after each of the next three releases in 2003, 2006 and 2009 years there was a sharp decline in the use of this name. Although by the fifth film in 2011 year the total number exceeds the usage before the first. After the fifth film, there is again an increase in the use of the name Dominic and after the 6th in 2013 year it declines. Data after 2015 are not available.\n\n\nCode - Filter data by name Dominic and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name == \"Dominic\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  geom_vline(xintercept=2001, linetype='dashed', color='red') + \\\n  geom_vline(xintercept=2003, linetype='dashed', color='gray') + \\\n  geom_vline(xintercept=2006, linetype='dashed', color='green') + \\\n  geom_vline(xintercept=2009, linetype='dashed', color='black') + \\\n  geom_vline(xintercept=2011, linetype='dashed', color='orange') + \\\n  geom_vline(xintercept=2013, linetype='dashed', color='#800080') + \\\n  geom_vline(xintercept=2015, linetype='dashed', color='pink') + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Dominic') + \\\n  labs(x='Year', y='People born with the name Dominic')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Dominic before the first ‘Fast and Furious’ release and throughout all releases",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#st1-reproduction-of-elliot-name-chart",
    "href": "250_Projects/project1.html#st1-reproduction-of-elliot-name-chart",
    "title": "Client Report - What’s in a Name?",
    "section": "ST1: Reproduction of “Elliot” Name Chart",
    "text": "ST1: Reproduction of “Elliot” Name Chart\nReproduce the chart Elliot using the data from the names_year.csv file.\nAccording to the data, we can see the history of the usage of Elliot name and E.T Releases: first in the middle of 1982 year, second in the 1985 year and third in 2002 year.\n\n\nCode - Filter data by name Elliot and year (&gt;=1950) and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name == \"Elliot\" & year &gt;=1950')\n# List of years\nyears = [\n  {'year': 1982.5,\n    'title': 'E. T. Released',\n   'position': 1976},\n  {'year': 1985,\n    'title': 'Second Release',\n   'position': 1992},\n  {'year': 2002,\n    'title': 'Third Release',\n   'position': 2008}]\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  scale_x_continuous(format=\"d\") + \\\n  scale_y_continuous(format=\"d\") + \\\n  ggtitle(f'Elliot... What?') + \\\n  labs(x='Year', y='Total')\n\nfor year in years:\n  chart += geom_vline(xintercept=year['year'], linetype='dashed', color='red') + \\\n  geom_text(label=year['title'], x=year['position'], y=d_name['Total'].max(), color='black')\n\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nFilter data by name Elliot from 1950 year and draw a graph with its three releases",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project4.html",
    "href": "250_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "250_Projects/project6.html",
    "href": "250_Projects/project6.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 6"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#elevator-pitch",
    "href": "250_Projects/project0.html#elevator-pitch",
    "title": "Client Report - Introduction",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nIn this project, I analyze the Palmer Penguins dataset to explore relationships between penguin species and their physical characteristics. By visualizing and summarizing key features such as flipper length, body mass, and bill dimensions, we aim to uncover trends and patterns that differentiate the species. Through the use of data visualization techniques, this report will provide insights into the characteristics of penguin populations.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\npenguins = load_penguins()\npenguins\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n344 rows × 8 columns",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#t1-recreate-charts",
    "href": "250_Projects/project0.html#t1-recreate-charts",
    "title": "Client Report - Introduction",
    "section": "T1: Recreate Charts",
    "text": "T1: Recreate Charts\nRecreate the example charts from PY4DS: CH2 Data Visualization of the textbook.\nAdd details here to answer the question but NOT like an assignment Q&A. You need to write your answers as a consulting solution report. A Client needs to understand the answer, but also needs to understand the decisions that went into the answer (when applicable).\ninclude figures in chunks and discuss your findings in the figure.\n\nYOU SHOULD HAVE QUALITY WRITING THAT DESCRIBES YOUR CHARTS AND TABLES.\nWE HIGHLY RECOMMEND GRAMMARLY TO FIX YOUR SPELLING AND GRAMMAR. WRITING TAKES TIME TO BE CLEAR. SPEND THE TIME TO PRACITCE.\nYOU SHOULD HAVE QUALITY COMMENTS THAT DESCRIBES YOUR CODES. OFTEN CODEERS WORK IN TEAMS AND YOU NEED TO HAVE QUALTIY COMMENTS FOR YOUR TEAM AND YOURSELF. YOU MAY NEED TO REVISIT CODE YOU WROTE OVER A YEAR AGO, AND IF YOU DONT COMMENT IT NOW YOU WONT REMEMBER WHY YOU DID WHAT YOU DID.\n\n\n\nRead and format data\n# Include and execute your (\nchart =   ggplot(data=penguins, mapping=aes(x=\"flipper_length_mm\", y=\"body_mass_g\")) + \\\n  geom_point(aes(color=\"species\", shape=\"species\")) + \\\n  geom_smooth(method=\"lm\") + \\\n  labs(\n        title=\"Body mass and flipper length\",\n        subtitle=\"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n        x=\"Flipper length (mm)\",\n        y=\"Body mass (g)\",\n        color=\"Species\",\n        shape=\"Species\",\n    )\n\nchart",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#task-3-table-used-to-create-the-above-chart",
    "href": "250_Projects/project0.html#task-3-table-used-to-create-the-above-chart",
    "title": "Client Report - Introduction",
    "section": "Task 3: Table used to create the above chart",
    "text": "Task 3: Table used to create the above chart\nInclude the table created from PY4DS: CH2 Data Visualization used to create the above chart\n\nPROVIDE TABLES THAT HELP ADDRESS THE QUESTIONS AND TASKS (IF APPLICABLE).\n\n\n\ntable example\n# Include and execute your code here",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project5.html",
    "href": "250_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "250_Projects/project3.html",
    "href": "250_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project2.html",
    "href": "250_Projects/project2.html",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "",
    "text": "This project helped me understand that it is always worth checking data for correctness. Despite the fact that we cannot always check how correct the data is, nevertheless, it must correspond to the type determined by the meaning of the column. Thus, if a column contains the value of the number of canceled flights, then it cannot be less than 0, and must also be a numeric value. It is important to consider all these nuances before starting to work with data. We can also take into account if the data is lost and has an empty value. Depending on the task, rows with these values may or may not be taken into account.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_flights = pd.read_json(\"https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json\")",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#elevator-pitch",
    "href": "250_Projects/project2.html#elevator-pitch",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "",
    "text": "This project helped me understand that it is always worth checking data for correctness. Despite the fact that we cannot always check how correct the data is, nevertheless, it must correspond to the type determined by the meaning of the column. Thus, if a column contains the value of the number of canceled flights, then it cannot be less than 0, and must also be a numeric value. It is important to consider all these nuances before starting to work with data. We can also take into account if the data is lost and has an empty value. Depending on the task, rows with these values may or may not be taken into account.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_flights = pd.read_json(\"https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json\")",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq1-standardization-of-missing-data-types",
    "href": "250_Projects/project2.html#cq1-standardization-of-missing-data-types",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ1: Standardization of Missing Data Types",
    "text": "CQ1: Standardization of Missing Data Types\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nAfter analyzing all the columns of the table, it was discovered that: - Airport Name had empty string (’’) as value - Month had missing data (‘n/a’) - Number of Delays Carrier had missing data (‘1500+’) - Year, Minutes Delayed Carrier, Minutes Delayd Nas had missing data (‘nan’) All these values on each columns have been replaced with the value NaN. The output shows an example of the final data in json format. Here we can see that num_of_delays_carrier has a null value.\nAlso in this example we can see that value for num_of_delays_late_aircraft is -999. This seams as incorrect for a purpose of the column but in its data type it is correct.\n\n\nCode - Finding missing data (‘n/a’, ’‘, ’nan’, ‘1500+’’) and fix it with NaN value\n# Find unique data for analizing data for missing values\n# unique_values_dict = {col: df_flights[col].unique() for col in df_flights.columns}\n# Replace missing data ('n/a', '', 'nan', '1500+') with NaN\ndf_flights = df_flights.replace({'': np.nan, 'n/a': np.nan, 'nan': np.nan, '1500+': np.nan})\n# Output example JSON row\nex = df_flights[df_flights.isna().any(axis=1)].iloc[0].to_json()\nex\n\n\n'{\"airport_code\":\"ATL\",\"airport_name\":\"Atlanta, GA: Hartsfield-Jackson Atlanta International\",\"month\":\"January\",\"year\":2005.0,\"num_of_flights_total\":35048,\"num_of_delays_carrier\":null,\"num_of_delays_late_aircraft\":-999,\"num_of_delays_nas\":4598,\"num_of_delays_security\":10,\"num_of_delays_weather\":448,\"num_of_delays_total\":8355,\"minutes_delayed_carrier\":116423.0,\"minutes_delayed_late_aircraft\":104415,\"minutes_delayed_nas\":207467.0,\"minutes_delayed_security\":297,\"minutes_delayed_weather\":36931,\"minutes_delayed_total\":465533}'",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq2-analysis-of-airport-delays",
    "href": "250_Projects/project2.html#cq2-analysis-of-airport-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ2: Analysis of Airport Delays",
    "text": "CQ2: Analysis of Airport Delays\nWhich airport has the worst delays? Describe the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nIn my understanding, the worst airport is the one that has the most delayed flights, since this does not give confidence whether my flight will be canceled or not, as well as the longest delay time, because this means that I have to plan too much time, taking into account possible postponement of the flight for subsequent business. According to this definition, a table was compiled in which we can see that the SFO airport is the worst in relation to it, since it most often has delays and in fact has the longest average delay time.\n\n\nCode - Analysis of Airport Delays\n# Add the average delay time in hours column\nworst_delays = df_flights.assign(hours_delayed_total = df_flights.minutes_delayed_total/df_flights.num_of_delays_total/60)\n# Group rows by the 'airport code'\nworst_delays = worst_delays.groupby(\"airport_code\").agg(\n    total_flights = ('num_of_flights_total', 'sum'),\n    total_delays = ('num_of_delays_total', 'sum'),\n    avg_delay_hours = ('hours_delayed_total', 'mean')\n)\n# Add the proportion of delayed flights column\nworst_delays['proportion_of_delayed'] = worst_delays['total_delays'] / worst_delays['total_flights']\n# Sort table by the average delay time in hours and proportion of delayed flights\nworst_delays = worst_delays.sort_values(['proportion_of_delayed', 'avg_delay_hours'], ascending=False)\n# Print out table\ndisplay(worst_delays)\n\n\n\n\n\n\nRating of airports {#cell-CQ2-table}\n\n\n\ntotal_flights\ntotal_delays\navg_delay_hours\nproportion_of_delayed\n\n\nairport_code\n\n\n\n\n\n\n\n\nSFO\n1630945\n425604\n1.017653\n0.260955\n\n\nORD\n3597588\n830825\n1.105717\n0.230939\n\n\nATL\n4430047\n902443\n0.989502\n0.203710\n\n\nIAD\n851571\n168467\n1.003245\n0.197831\n\n\nSAN\n917862\n175132\n0.784028\n0.190804\n\n\nDEN\n2513974\n468519\n0.882581\n0.186366\n\n\nSLC\n1403384\n205160\n0.823587\n0.146189",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq3-optimal-month-for-minimizing-flight-delays",
    "href": "250_Projects/project2.html#cq3-optimal-month-for-minimizing-flight-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ3: Optimal Month for Minimizing Flight Delays",
    "text": "CQ3: Optimal Month for Minimizing Flight Delays\nWhat is the best month to fly if you want to avoid delays of any length? Describe the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nIn this graph we can see the percentage of delayed flights for each month. So we see that December has the most flight delays, so there’s a good chance our flight will be delayed this month too. While in September, according to statistics, the least flight delays occur. Therefore, if you are planning a trip by plane, then the best month for your plans to best match your expectations is September.\n\n\nCode - Analyse data for each month for minimizing flight delays\n# clear wrong data (February)\ndf_flights.replace('Febuary', 'February', inplace=True)\n# Delete all rows with no named month\nd_months = df_flights.query(\"@pd.notnull(month)\")\n# Group rows by month\nd_months = d_months.groupby('month').agg(\n    total_flights = ('num_of_flights_total', 'sum'),\n    total_delays = ('num_of_delays_total', 'sum')\n).reset_index()\n# Add the proportion of delayed flights in % column\nd_months['proportion_of_delayed'] = round(d_months['total_delays'] / d_months['total_flights'], 2)*100\n# Sort table by the 'months'\nmonth_dict = {'January':1,'February':2,'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\nd_months = d_months.sort_values(['month'], key = lambda x : x.apply (lambda x : month_dict[x]), ascending=True).reset_index(drop=True)\n\n# Identify best and worst months\nbest_month = d_months.loc[d_months['proportion_of_delayed'].idxmin(), 'month']\nworst_month = d_months.loc[d_months['proportion_of_delayed'].idxmax(), 'month']\n\nd_months['color'] = np.where(d_months['month'] == best_month, 'blue', \n                             np.where(d_months['month'] == worst_month, 'red', 'gray'))\n\n# Draw chart\nchart = ggplot(d_months, aes(x='month', y='proportion_of_delayed', fill='color')) + \\\n    geom_bar(stat='identity') + \\\n      scale_fill_identity() + \\\n    ggtitle('Proportion of Delayed Flights by Month') + \\\n    xlab('Month') + \\\n    ylab('Proportion of Delayed Flights')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nChart shows The proportion of delays for each month and indicate best and worst of it",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq4-calculation-of-total-weather-related-flight-delays",
    "href": "250_Projects/project2.html#cq4-calculation-of-total-weather-related-flight-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ4: Calculation of Total Weather-Related Flight Delays",
    "text": "CQ4: Calculation of Total Weather-Related Flight Delays\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\na. 100% of delayed flights in the Weather category are due to weather b. 30% of all delayed flights in the Late-Arriving category are due to weather c. From April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%\nWhile studying the data necessary for the calculations, it was discovered that flights delayed due to a late plane had incorrect data in the form of -999, which I corrected to the average value for this column. The remaining columns required for calculations had data correct for calculations.\n\n\nCode - Calculation of Total Weather-Related Flight Delays\n# Fill missing data\n# Use mean value for missing data\nmean_late_aircraft = df_flights.num_of_delays_late_aircraft.mean()\ndf_flights.replace(-999, mean_late_aircraft, inplace=True)\ndf_flights.fillna(mean_late_aircraft, inplace=True)\n# calculate delays by weather\npredata = df_flights.assign(delays_by_weather_months = lambda x: 0.4*x.num_of_delays_nas if str(x.month) in ['April', 'May', 'June', 'July', 'August'] else 0.65*x.num_of_delays_nas)\npredata = predata.assign(delays_by_weather = lambda x: x.num_of_delays_weather + 0.3*x.num_of_delays_late_aircraft + x.delays_by_weather_months)\n\n# Columns to include in the resut table\ncolumns_to_include = ['airport_code', 'airport_name', 'month', 'num_of_flights_total', 'num_of_delays_total', 'num_of_delays_weather', 'num_of_delays_late_aircraft', 'num_of_delays_nas', 'delays_by_weather']\n# Filter DataFrame to include only desired columns\ndata4 = predata[columns_to_include]\ntable4 = data4.head(5)\n\ntable4\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nnum_of_flights_total\nnum_of_delays_total\nnum_of_delays_weather\nnum_of_delays_late_aircraft\nnum_of_delays_nas\ndelays_by_weather\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n35048\n8355\n448\n1017.844156\n4598\n3742.053247\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n12687\n3153\n233\n928.000000\n935\n1119.150000\n\n\n2\nIAD\n1017.844156\nJanuary\n12381\n2430\n61\n1058.000000\n895\n960.150000\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n28194\n9178\n306\n2255.000000\n5415\n4502.250000\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n7283\n1952\n56\n680.000000\n638\n674.700000",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq5-analysis-of-weather-related-flight-delays-by-airport",
    "href": "250_Projects/project2.html#cq5-analysis-of-weather-related-flight-delays-by-airport",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ5: Analysis of Weather-Related Flight Delays by Airport",
    "text": "CQ5: Analysis of Weather-Related Flight Delays by Airport\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Describe what you learn from this graph.\nAccording to statistics and taking into account all data errors on the histogram, we can see the following: Siberian Federal District, ORD, ATL have approximately the same high percentage of flights delayed due to weather - 40+%. This means that when choosing these airports, you should pay attention to the expected weather when flying in that region. SAN Airport has the lowest percentage of flights delayed due to weather - 30%.\n\n\nCode - Filter data of Weather-Related Flight Delays by Airport\ndata5 = predata.groupby(\"airport_code\").agg(\n    total_num_of_delays = ('num_of_delays_total', 'sum'),\n    num_of_delays_weather = ('num_of_delays_weather', 'sum'),\n    numu_of_delays_late_aircraft = ('num_of_delays_late_aircraft', 'sum'),\n    num_of_delays_nas = ('num_of_delays_nas', 'sum'),\n    total_num_of_delays_by_weather = ('delays_by_weather', 'sum')\n).reset_index()\n# Add the 'proportion of delayed flights by weather' column\ndata5 = data5.assign(proportion_of_delayed_flights_by_weather = lambda x: round(x.total_num_of_delays_by_weather/x.total_num_of_delays, 2)*100)\n\nchart = ggplot(data5, aes(x='airport_code', y='proportion_of_delayed_flights_by_weather')) + \\\n    geom_bar(stat='identity') + \\\n    ggtitle('Proportion of Delayed Flights by Month') + \\\n    xlab('Airport code') + \\\n    ylab('Rate of delayed flights by weather in %')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing Weather-Related Flight Delays by Airport",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#sq1-comparative-analysis-of-flight-delay-types",
    "href": "250_Projects/project2.html#sq1-comparative-analysis-of-flight-delay-types",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "SQ1: Comparative Analysis of Flight Delay Types",
    "text": "SQ1: Comparative Analysis of Flight Delay Types\nWhich delay is the worst delay? Create a similar analysis as above for Weahter Delay with: Carrier Delay and Security Delay. Compare the proportion of delay for each of the three categories in a Chart and a Table. Describe your results.\nWhen examining the data needed for the calculations, it was discovered that the required columns had incorrect data, which I corrected to the average of that column. According to statistics and taking into account all the data errors on the histogram, we see the following: the largest number of delays is associated with weather - 39%, the smallest number of delays is associated with security - almost 0%.\n\n\nCode - Filter data for Comparison of Delay Percentage by Delay Type\n# Clear num_of_delays_carrier\npredata['Numeric_Column'] = pd.to_numeric(predata['num_of_delays_carrier'], errors='coerce')\nmean_value = predata['Numeric_Column'].mean()\npredata['num_of_delays_carrier'] = predata['Numeric_Column'].fillna(mean_value)\n# Clear num_of_delays_security\npredata['Numeric_Column'] = pd.to_numeric(predata['num_of_delays_security'], errors='coerce')\nmean_value = predata['Numeric_Column'].mean()\npredata['num_of_delays_security'] = predata['Numeric_Column'].fillna(mean_value)\n\npredata['Numeric_Column'] = 1\ndata6 = predata.groupby(\"Numeric_Column\").agg(\n    total_num_of_delays = ('num_of_delays_total', 'sum'),\n    num_of_delays_weather = ('num_of_delays_weather', 'sum'),\n    numu_of_delays_late_aircraft = ('num_of_delays_late_aircraft', 'sum'),\n    num_of_delays_nas = ('num_of_delays_nas', 'sum'),\n    total_num_of_delays_by_weather = ('delays_by_weather', 'sum'),\n    num_of_delays_carrier = ('num_of_delays_carrier', 'sum'),\n    num_of_delays_security = ('num_of_delays_security', 'sum')\n).reset_index()\n# Add the 'proportion of delayed flights by weather' column\ndata6 = data6.assign(rate_of_delayed_flights_by_weather = lambda x: round(x.total_num_of_delays_by_weather/x.total_num_of_delays, 2)*100)\ndata6 = data6.assign(rate_of_delayed_flights_by_carrier = lambda x: round(x.num_of_delays_carrier/x.total_num_of_delays, 2)*100)\ndata6 = data6.assign(rate_of_delayed_flights_by_security = lambda x: round(x.num_of_delays_security/x.total_num_of_delays, 2)*100)\n# Columns to include in the resut table\ncolumns_to_include = ['rate_of_delayed_flights_by_weather', 'rate_of_delayed_flights_by_carrier', 'rate_of_delayed_flights_by_security']\n# Filter DataFrame to include only desired columns\ndata = data6[columns_to_include]\ndata\n\n\n\n\n\n\n\n\n\nrate_of_delayed_flights_by_weather\nrate_of_delayed_flights_by_carrier\nrate_of_delayed_flights_by_security\n\n\n\n\n0\n39.0\n21.0\n0.0\n\n\n\n\n\n\n\n\n\nCode - Creating graph for Comparison of Delay Percentage by Delay Type\ndelay_comparison = data6[['Numeric_Column', 'rate_of_delayed_flights_by_carrier', 'rate_of_delayed_flights_by_security', 'rate_of_delayed_flights_by_weather']]\n\ndelay_comparison_melted = delay_comparison.melt(id_vars='Numeric_Column', \n                                                var_name='Delay_Type', \n                                                value_name='Delay_Percentage')\n\n# График с пропорциями задержек по типам\nchart = ggplot(delay_comparison_melted, aes(x='Delay_Type', y='Delay_Percentage', fill='Delay_Type')) + \\\n    geom_bar(stat='identity', position='dodge') + \\\n    ggtitle('Comparison of Delay Types by Delay Type') + \\\n    xlab('Delay_Type') + \\\n    ylab('Percentage of Delays') + \\\n    scale_fill_brewer(type='qual', palette='Set1')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the dependence of delay persentage by delay type",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Physicist, Mathematician, Cambridge professor.\n\nisaac@applesdofall.org | My wikipedia page\n\n\n\nStanding on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples.\n\n\n\n\n1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow\n\n\n\n\n2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France\n\n\n\n\n\n\n1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001\n\n\n\n\n1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "250_projects.html",
    "href": "250_projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0 - Introduction\nProject 1 - What’s in a Name\nProject 2 - Late Flights and Missing Data (JSON)\nProject 3 - Finding Relationships in Baseball\nProject 4 - Can you Predict That?\nProject 5 - The War with StarWars\nProject 6 - Git Your Portfolio Online",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "250_projects.html#repo-for-all-my-projects",
    "href": "250_projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0 - Introduction\nProject 1 - What’s in a Name\nProject 2 - Late Flights and Missing Data (JSON)\nProject 3 - Finding Relationships in Baseball\nProject 4 - Can you Predict That?\nProject 5 - The War with StarWars\nProject 6 - Git Your Portfolio Online",
    "crumbs": [
      "DS250 Projects"
    ]
  }
]