[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Final project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\n\n\n\n\nMid-project video\nFinal project\n\nMarkDown Basics"
  },
  {
    "objectID": "index.html#project0---introduction",
    "href": "index.html#project0---introduction",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Final project"
  },
  {
    "objectID": "index.html#project1---whats-in-a-name",
    "href": "index.html#project1---whats-in-a-name",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project2---late-flights-and-missing-data-json",
    "href": "index.html#project2---late-flights-and-missing-data-json",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project3---finding-relationships-in-baseball",
    "href": "index.html#project3---finding-relationships-in-baseball",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project4---can-you-predict-that",
    "href": "index.html#project4---can-you-predict-that",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project5---the-war-with-star-wars",
    "href": "index.html#project5---the-war-with-star-wars",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project"
  },
  {
    "objectID": "index.html#project6---git-your-portfolio-online",
    "href": "index.html#project6---git-your-portfolio-online",
    "title": "Student of 250DS class Fall2024 semester",
    "section": "",
    "text": "Mid-project video\nFinal project\n\nMarkDown Basics"
  },
  {
    "objectID": "Templates/DS250_Template.html",
    "href": "Templates/DS250_Template.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "THIS .qmd IS INSTRUCTIONAL AND SHOULD NOT BE USED TO WRITE YOUR REPORTS (EXCEPTION - PROJECT 0). THERE IS ANOTHER TEMPLATE FILE FOR THAT. YOU WILL NEED TO PREVIEW THE REPORT TO PRODUCE A .html FILE. YOU WILL SUBMIT THE .html FILE ON CANVAS."
  },
  {
    "objectID": "Templates/DS250_Template.html#elevator-pitch",
    "href": "Templates/DS250_Template.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nA SHORT (2-3 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS. (Note: this is not a summary of the project, but a summary of the results.)\nA Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/mpg/mpg.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-1",
    "href": "Templates/DS250_Template.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 1",
    "text": "Question|Task 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\nAdd details here to answer the question but NOT like an assignment Q&A. You need to write your answers as a consulting solution report. A Client needs to understand the answer, but also needs to understand the decisions that went into the answer (when applicable).\ninclude figures in chunks and discuss your findings in the figure.\n\nYOU SHOULD HAVE QUALITY WRITING THAT DESCRIBES YOUR CHARTS AND TABLES.\nWE HIGHLY RECOMMEND GRAMMARLY TO FIX YOUR SPELLING AND GRAMMAR. WRITING TAKES TIME TO BE CLEAR. SPEND THE TIME TO PRACITCE.\nYOU SHOULD HAVE QUALITY COMMENTS THAT DESCRIBES YOUR CODES. OFTEN CODEERS WORK IN TEAMS AND YOU NEED TO HAVE QUALTIY COMMENTS FOR YOUR TEAM AND YOURSELF. YOU MAY NEED TO REVISIT CODE YOU WROTE OVER A YEAR AGO, AND IF YOU DONT COMMENT IT NOW YOU WONT REMEMBER WHY YOU DID WHAT YOU DID.\n\n\n\nRead and format data\n# Include and execute your code here"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-2",
    "href": "Templates/DS250_Template.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 2",
    "text": "Question|Task 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\n\nplot example\n# Include and execute your code here\n\n(\n  ggplot(df.head(500), aes(x='displ', y='hwy')) + geom_point()\n)\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nMy useless chart"
  },
  {
    "objectID": "Templates/DS250_Template.html#questiontask-3",
    "href": "Templates/DS250_Template.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "Question|Task 3",
    "text": "Question|Task 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\n\nPROVIDE TABLES THAT HELP ADDRESS THE QUESTIONS AND TASKS (IF APPLICABLE).\n\n\n\ntable example\n# Include and execute your code here\nmydat = (df.head(1000)\n    .groupby('manufacturer')\n    .sum()\n    .reset_index()\n    .tail(10)\n    .filter([\"manufacturer\",\"displ\",\"cty\", \"hwy\"])\n)\n\ndisplay(mydat)\n\n\n\n\n\n\ntable example {#cell-Q1-table}\n\n\n\nmanufacturer\ndispl\ncty\nhwy\n\n\n\n\n5\nhyundai\n34.0\n261\n376\n\n\n6\njeep\n36.6\n108\n141\n\n\n7\nland rover\n17.2\n46\n66\n\n\n8\nlincoln\n16.2\n34\n51\n\n\n9\nmercury\n17.6\n53\n72\n\n\n10\nnissan\n42.5\n235\n320\n\n\n11\npontiac\n19.8\n85\n132\n\n\n12\nsubaru\n34.4\n270\n358\n\n\n13\ntoyota\n100.4\n630\n847\n\n\n14\nvolkswagen\n60.9\n565\n789\n\n\n\n\n\n\n\nNote: Non executing Python Snippets include (3) ``` followed by (3) more ```, each on their own line. These are not single quotes, they are the key left of the number 1 key on the keyboard. The top row can include the language of code that is pasted inbetween the ``` marks.\nNote: These also work in Slack and it is expected they are used for any code shared in that app. No screen shots allowed."
  },
  {
    "objectID": "250_Projects/project1.html",
    "href": "250_Projects/project1.html",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "Through this project I had the opportunity to become more familiar with working with graphs when searching for specific information. It was very interesting for me to study the history of the use of various names, since it gives us an understanding of how many people with a specific name were born in certain years and how old they might be now. In the example with question 2 about the name Brittany, I was interested in how much our association with name and age coincides with reality.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_names = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#elevator-pitch",
    "href": "250_Projects/project1.html#elevator-pitch",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "Through this project I had the opportunity to become more familiar with working with graphs when searching for specific information. It was very interesting for me to study the history of the use of various names, since it gives us an understanding of how many people with a specific name were born in certain years and how old they might be now. In the example with question 2 about the name Brittany, I was interested in how much our association with name and age coincides with reality.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_names = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq1-comparing-name-anastasia-popularity-over-time",
    "href": "250_Projects/project1.html#cq1-comparing-name-anastasia-popularity-over-time",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ1: Comparing Name Anastasia Popularity Over Time",
    "text": "CQ1: Comparing Name Anastasia Popularity Over Time\nHow does your name at your birth year compare to its use historically?\nUntil the 1980s, the popularity of this name was 0-200 children per year, which is quite small, considering that most of the time this figure was below 100. Since the 1980s, active use of this name began. In less than 10 years, its popularity has quadrupled. By the year of my birth (1998), almost 1.5 times. At the moment, this indicator continues to grow.\n\n\nCode - Filter data by name Anastasia and draw a graph with point birth year (1998)\n# Filter data by name\nd_name = df_names.query('name == \"Anastasia\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  geom_vline(xintercept=1998, linetype='dashed', color='green', size=1) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Anastasia') + \\\n  labs(x='Year', y='People born with the name Anastasia')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Anastasia before, on and after 1998",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq2-age-estimation-based-on-name-britany",
    "href": "250_Projects/project1.html#cq2-age-estimation-based-on-name-britany",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ2: Age Estimation Based on Name Britany",
    "text": "CQ2: Age Estimation Based on Name Britany\nIf you talked to someone named Brittany on the phone, what is your guess of their age? What ages would you not guess?\nFor me, the name Brittany is associated with a young woman of about 20. I definitely would not have guessed that she could be 45 or older if the voice itself did not indicate otherwise. However, according to available data, most people with this name are 33-34 years old today.\n\n\nCode - Filter data by name Brittany and draw a graph\n# Filter data by name\nd_name = df_names.query('name == \"Brittany\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Brittany') + \\\n  labs(x='Year', y='People born with the name Brittany')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Brittany",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq3-comparative-analysis-of-christian-names-from-1920-to-2000",
    "href": "250_Projects/project1.html#cq3-comparative-analysis-of-christian-names-from-1920-to-2000",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ3: Comparative Analysis of Christian Names from 1920 to 2000",
    "text": "CQ3: Comparative Analysis of Christian Names from 1920 to 2000\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names.\nPrior to 1970, the most popular name was Mary. It was given to their children 2-4 times more often than the name Paul, which is in second place. An interesting point is that from 1970 to 2000 the use of the names Mary and Paul is almost the same. Martha and Peter are quite rare names for those years from 19021 to 2000. However, it is interesting to note that initially the name Martha was preferable, but after 1950 the situation changed, so that the name Peter became more popular. By 2000, the general usage of all four names was nearly the same.\n\n\nCode - Filter data by Christian names and year (1920-2000) and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name in [\"Mary\", \"Martha\", \"Peter\", \"Paul\"] & year &gt;=1920 & year &lt;=2000')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(aes(color='name'), size=1) + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the Christian names') + \\\n  labs(\n    x='Year',\n    y='People born with the Christian names',\n    color='Christian names')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the names between 1920 and 2000 years",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#cq4-impact-of-a-famous-movie-on-name-usage",
    "href": "250_Projects/project1.html#cq4-impact-of-a-famous-movie-on-name-usage",
    "title": "Client Report - What’s in a Name?",
    "section": "CQ4: Impact of a Famous Movie on Name Usage",
    "text": "CQ4: Impact of a Famous Movie on Name Usage\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI analyzed data on the name Dominic from the movie “Fast and the Furious”. According to the data, before the release of the first film in 2001 year, the name was already growing in popularity. After the first film, we see an increase in the use of this name. However, after each of the next three releases in 2003, 2006 and 2009 years there was a sharp decline in the use of this name. Although by the fifth film in 2011 year the total number exceeds the usage before the first. After the fifth film, there is again an increase in the use of the name Dominic and after the 6th in 2013 year it declines. Data after 2015 are not available.\n\n\nCode - Filter data by name Dominic and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name == \"Dominic\"')\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  geom_vline(xintercept=2001, linetype='dashed', color='red') + \\\n  geom_vline(xintercept=2003, linetype='dashed', color='gray') + \\\n  geom_vline(xintercept=2006, linetype='dashed', color='green') + \\\n  geom_vline(xintercept=2009, linetype='dashed', color='black') + \\\n  geom_vline(xintercept=2011, linetype='dashed', color='orange') + \\\n  geom_vline(xintercept=2013, linetype='dashed', color='#800080') + \\\n  geom_vline(xintercept=2015, linetype='dashed', color='pink') + \\\n  scale_x_continuous(format=\"d\") + \\\n  ggtitle(f'History of use of the name Dominic') + \\\n  labs(x='Year', y='People born with the name Dominic')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the history of the name Dominic before the first ‘Fast and Furious’ release and throughout all releases",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project1.html#st1-reproduction-of-elliot-name-chart",
    "href": "250_Projects/project1.html#st1-reproduction-of-elliot-name-chart",
    "title": "Client Report - What’s in a Name?",
    "section": "ST1: Reproduction of “Elliot” Name Chart",
    "text": "ST1: Reproduction of “Elliot” Name Chart\nReproduce the chart Elliot using the data from the names_year.csv file.\nAccording to the data, we can see the history of the usage of Elliot name and E.T Releases: first in the middle of 1982 year, second in the 1985 year and third in 2002 year.\n\n\nCode - Filter data by name Elliot and year (&gt;=1950) and draw a graph\n# Filter data by name and year\nd_name = df_names.query('name == \"Elliot\" & year &gt;=1950')\n# List of years\nyears = [\n  {'year': 1982.5,\n    'title': 'E. T. Released',\n   'position': 1976},\n  {'year': 1985,\n    'title': 'Second Release',\n   'position': 1992},\n  {'year': 2002,\n    'title': 'Third Release',\n   'position': 2008}]\n# Draw a graph\nchart = ggplot(d_name, aes('year', 'Total')) + \\\n  geom_line(color='blue') + \\\n  geom_area(fill='lightblue', alpha=0.6) + \\\n  scale_x_continuous(format=\"d\") + \\\n  scale_y_continuous(format=\"d\") + \\\n  ggtitle(f'Elliot... What?') + \\\n  labs(x='Year', y='Total')\n\nfor year in years:\n  chart += geom_vline(xintercept=year['year'], linetype='dashed', color='red') + \\\n  geom_text(label=year['title'], x=year['position'], y=d_name['Total'].max(), color='black')\n\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nFilter data by name Elliot from 1950 year and draw a graph with its three releases",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "250_Projects/project4.html",
    "href": "250_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "250_Projects/project6.html",
    "href": "250_Projects/project6.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 6"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#elevator-pitch",
    "href": "250_Projects/project0.html#elevator-pitch",
    "title": "Client Report - Introduction",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nIn this project, I analyze the Palmer Penguins dataset to explore relationships between penguin species and their physical characteristics. By visualizing and summarizing key features such as flipper length, body mass, and bill dimensions, we aim to uncover trends and patterns that differentiate the species. Through the use of data visualization techniques, this report will provide insights into the characteristics of penguin populations.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\npenguins = load_penguins()\npenguins\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n344 rows × 8 columns",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#t1-recreate-charts",
    "href": "250_Projects/project0.html#t1-recreate-charts",
    "title": "Client Report - Introduction",
    "section": "T1: Recreate Charts",
    "text": "T1: Recreate Charts\nRecreate the example charts from PY4DS: CH2 Data Visualization of the textbook.\nAdd details here to answer the question but NOT like an assignment Q&A. You need to write your answers as a consulting solution report. A Client needs to understand the answer, but also needs to understand the decisions that went into the answer (when applicable).\ninclude figures in chunks and discuss your findings in the figure.\n\nYOU SHOULD HAVE QUALITY WRITING THAT DESCRIBES YOUR CHARTS AND TABLES.\nWE HIGHLY RECOMMEND GRAMMARLY TO FIX YOUR SPELLING AND GRAMMAR. WRITING TAKES TIME TO BE CLEAR. SPEND THE TIME TO PRACITCE.\nYOU SHOULD HAVE QUALITY COMMENTS THAT DESCRIBES YOUR CODES. OFTEN CODEERS WORK IN TEAMS AND YOU NEED TO HAVE QUALTIY COMMENTS FOR YOUR TEAM AND YOURSELF. YOU MAY NEED TO REVISIT CODE YOU WROTE OVER A YEAR AGO, AND IF YOU DONT COMMENT IT NOW YOU WONT REMEMBER WHY YOU DID WHAT YOU DID.\n\n\n\nRead and format data\n# Include and execute your (\nchart =   ggplot(data=penguins, mapping=aes(x=\"flipper_length_mm\", y=\"body_mass_g\")) + \\\n  geom_point(aes(color=\"species\", shape=\"species\")) + \\\n  geom_smooth(method=\"lm\") + \\\n  labs(\n        title=\"Body mass and flipper length\",\n        subtitle=\"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n        x=\"Flipper length (mm)\",\n        y=\"Body mass (g)\",\n        color=\"Species\",\n        shape=\"Species\",\n    )\n\nchart",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project0.html#task-3-table-used-to-create-the-above-chart",
    "href": "250_Projects/project0.html#task-3-table-used-to-create-the-above-chart",
    "title": "Client Report - Introduction",
    "section": "Task 3: Table used to create the above chart",
    "text": "Task 3: Table used to create the above chart\nInclude the table created from PY4DS: CH2 Data Visualization used to create the above chart\n\nPROVIDE TABLES THAT HELP ADDRESS THE QUESTIONS AND TASKS (IF APPLICABLE).\n\n\n\ntable example\n# Include and execute your code here",
    "crumbs": [
      "DS250 Projects",
      "Project 0"
    ]
  },
  {
    "objectID": "250_Projects/project5.html",
    "href": "250_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "250_Projects/project3.html",
    "href": "250_Projects/project3.html",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "",
    "text": "Achievements in sports are always an analysis of several areas. Unfortunately, the overall percentage of victories for all time does not show ideal indicators for a player, since one could play only one game and the team could win, while another player will play 10 games and lose at least one of them, already put him in second place. Also important are other factors when comparing players and teams, which I considered in this project, during the study of data analysis through SQL queries.\n\n\nConnect to database with project data\nsqlite_file = 'lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#elevator-pitch",
    "href": "250_Projects/project3.html#elevator-pitch",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "",
    "text": "Achievements in sports are always an analysis of several areas. Unfortunately, the overall percentage of victories for all time does not show ideal indicators for a player, since one could play only one game and the team could win, while another player will play 10 games and lose at least one of them, already put him in second place. Also important are other factors when comparing players and teams, which I considered in this project, during the study of data analysis through SQL queries.\n\n\nConnect to database with project data\nsqlite_file = 'lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#cq1-byu-idaho-baseball-players",
    "href": "250_Projects/project3.html#cq1-byu-idaho-baseball-players",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "CQ1: BYU-Idaho baseball players",
    "text": "CQ1: BYU-Idaho baseball players\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\nAccording to the data we have information only on two students. Analyzing each of them we see that the player with ID stephga01 had a salary increase from 1997 to 2001, after which his salary fell. The player with ID lindsma01 from 2007 to 2009 playing for the FLO team had a small salary increase. But after moving to another team in 2010 his salary increased 4 times. And although in the end by 2014 his salary increased more than 2 times, after 2010 he changed 2 more teams until in 2013 he joined the CHA team with a salary decrease, which was compensated a year later in 2014.\n\n\nCode - Find all players from BYU-Idaho and their Salaries by year and team\nq = '''\n    SELECT DISTINCT sal.playerID, sal.salary, sal.yearID, sal.teamID\n    FROM salaries sal\n    JOIN collegeplaying cp ON cp.playerID = sal.playerID\n    JOIN schools sc ON cp.schoolID = sc.schoolID\n    WHERE sc.name_full='Brigham Young University-Idaho'\n    ORDER BY sal.salary DESC\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nBYU-Idaho players salaries {#cell-CQ1-table}\n\n\n\nplayerID\nsalary\nyearID\nteamID\n\n\n\n\n0\nlindsma01\n4000000.0\n2014\nCHA\n\n\n1\nlindsma01\n3600000.0\n2012\nBAL\n\n\n2\nlindsma01\n2800000.0\n2011\nCOL\n\n\n3\nlindsma01\n2300000.0\n2013\nCHA\n\n\n4\nlindsma01\n1625000.0\n2010\nHOU\n\n\n5\nstephga01\n1025000.0\n2001\nSLN\n\n\n6\nstephga01\n900000.0\n2002\nSLN\n\n\n7\nstephga01\n800000.0\n2003\nSLN\n\n\n8\nstephga01\n550000.0\n2000\nSLN\n\n\n9\nlindsma01\n410000.0\n2009\nFLO\n\n\n10\nlindsma01\n395000.0\n2008\nFLO\n\n\n11\nlindsma01\n380000.0\n2007\nFLO\n\n\n12\nstephga01\n215000.0\n1999\nSLN\n\n\n13\nstephga01\n185000.0\n1998\nPHI\n\n\n14\nstephga01\n150000.0\n1997\nPHI",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#cq2-players-batting-average",
    "href": "250_Projects/project3.html#cq2-players-batting-average",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "CQ2: Players batting average",
    "text": "CQ2: Players batting average\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\na. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\nIn this list we see the top 5 players who have 100% batting in certain years. However, these figures may not be entirely correct, as they take into account players who had at least one batting and if it was successful, they became the leaders in the list.\n\n\nCode - Finding Top-5 players on batting average\nq = '''\n    SELECT playerID, yearID,\n      ROUND((1.0*H/AB), 2) AS batting_avr\n    FROM batting\n    WHERE AB &gt;= 1\n    ORDER BY batting_avr DESC, playerID ASC\n    LIMIT 5\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nTop-5 players on batting average {#cell-CQ2-table-a}\n\n\n\nplayerID\nyearID\nbatting_avr\n\n\n\n\n0\naberal01\n1957\n1.0\n\n\n1\nabernte02\n1960\n1.0\n\n\n2\nabramge01\n1923\n1.0\n\n\n3\nacklefr01\n1964\n1.0\n\n\n4\nalanirj01\n2019\n1.0\n\n\n\n\n\n\n\nb. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\nIn this list we see the top 5 players who have the highest batting average in certain years. By counting players who have at least 10 batting averages this year we have improved the accuracy of the table by looking at the results on multiple attempts.\n\n\nCode - Finding Top-5 players on batting average with at least 10 at bats each year\nq = '''\n    SELECT playerID, yearID,\n      ROUND((1.0*H/AB), 2) AS batting_avr\n    FROM batting\n    WHERE AB &gt;= 10\n    ORDER BY batting_avr DESC, playerID ASC\n    LIMIT 5\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nTop-5 players on batting average (at least 10 at bats that year) {#cell-CQ2-table-b}\n\n\n\nplayerID\nyearID\nbatting_avr\n\n\n\n\n0\ncarsoma01\n2013\n0.64\n\n\n1\nnymanny01\n1974\n0.64\n\n\n2\naltizda01\n1910\n0.60\n\n\n3\njohnsde01\n1975\n0.60\n\n\n4\nsilvech01\n1948\n0.57\n\n\n\n\n\n\n\nc. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\nIn this list we see the top 5 players who have the highest batting average throughout their playing career. Considering players who have at least 100 batting averages throughout their career, we have improved the accuracy of the table by looking at the results over multiple attempts throughout their playing career.\n\n\nCode - Finding Top-5 players on batting average over their entire careers with at least 100 at bats\nq = '''\n    SELECT playerID,\n      ROUND((1.0*SUM(H)/SUM(AB)), 2) AS batting_avr\n    FROM batting\n    GROUP BY playerID\n    HAVING SUM(AB) &gt;= 100\n    ORDER BY batting_avr DESC, playerID ASC\n    LIMIT 5\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nTop-5 players on batting average over their entire careers (At least 100 at bats) {#cell-CQ2_table_c}\n\n\n\nplayerID\nbatting_avr\n\n\n\n\n0\ncobbty01\n0.37\n\n\n1\nbarnero01\n0.36\n\n\n2\nhornsro01\n0.36\n\n\n3\njacksjo01\n0.36\n\n\n4\nmeyerle01\n0.36",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#cq3-comparison-of-two-basketball-teams",
    "href": "250_Projects/project3.html#cq3-comparison-of-two-basketball-teams",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "CQ3: Comparison of two basketball teams",
    "text": "CQ3: Comparison of two basketball teams\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Lets-Plot to visualize the comparison. What do you learn?\nI compared the top two teams by win percentage relative to their salaries (with available salary data). Among the top 2 teams by win percentage, OAC is in first place. However, regarding salaries, we see that their average salary is more than two times less than that of the number 2 team. This gap began in 1996. Before that year, the average salary in both teams was approximately the same, after which UAC reduced the salary, and BRS, on the contrary, increased it. However, this did not affect the results much. Although it is also worth separately considering the graph of win percentage for these years. Perhaps such a salary increase was strategically important for attracting more experienced players, which in general, in the history of the team, helped them become more stable in recent years.\n\n\nCode - Finding Average Salaries for each year for two best teams by win rate.\nq = '''\n    WITH bestteams AS (\n      SELECT t.teamID, tf.franchName,\n        SUM(t.W) * 1.0 / SUM(t.G) AS win_rate\n      FROM salaries slr\n      JOIN teams t ON slr.teamID = t.teamID\n      JOIN teamsfranchises tf ON t.teamID = tf.franchID\n      GROUP BY t.teamID\n      ORDER BY win_rate DESC\n      LIMIT 2\n    )\n    SELECT bt.franchName, slr.yearID as year, ROUND(AVG(slr.salary), 2) AS salary\n    FROM bestteams bt\n    JOIN salaries slr ON bt.teamID = slr.teamID\n    GROUP BY bt.teamID, slr.yearID\n    '''\ntable = pd.read_sql_query(q,con)\n\n\n# Draw chart\nchart = (ggplot(table, aes('year', 'salary', color='franchName')) + \\\n        geom_line(size=1.5) + \\\n        geom_point(size=3)) + \\\n        scale_x_continuous(format=\"d\") + \\\n        ggtitle(f'Comparison of Two Best Teams by Salary') + \\\n        labs(\n          x='Year',\n          y='Salary',\n          color='Team names')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nComparison of Two Best Teams (by win rate) by Salary",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#sq1-advanced-salary-distribution-by-position-with-case-statement",
    "href": "250_Projects/project3.html#sq1-advanced-salary-distribution-by-position-with-case-statement",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "SQ1: Advanced Salary Distribution by Position (with Case Statement)",
    "text": "SQ1: Advanced Salary Distribution by Position (with Case Statement)\nWrite an SQL query that provides a summary table showing the average salary for players in each position (e.g., pitcher, catcher, outfielder) across all yearslr. Include the following columns: * position * average_salary * total_players * highest_salary\nThe highest_salary column should display the highest salary ever earned by a player in that position. If no player in that position has a recorded salary, display “N/A” for the highest salary.\nAdditionally, create a new column called salary_category using a case statement: * If the average salary is above $1 million, categorize it as “High Salary.” * If the average salary is between $500,000 and $1 million, categorize it as “Medium Salary.” * Otherwise, categorize it as “Low Salary.”\nOrder the table by average salary in descending order.\nPrint the top 10 rows of this summary table.\nAll positions have a high salary on average. Although it is interesting to note that at their maximum there are 4 positions that had identical salaries.\n\n\nCode - Find Top-10 positions by average salary\nq = '''\n    SELECT \n      fld.pos AS position,\n      ROUND(AVG(slr.salary), 2) AS avg_salary,\n      COUNT(DISTINCT slr.playerID) AS total_players,\n      CASE \n          WHEN MAX(slr.salary) IS NULL THEN 'N/A'\n          ELSE CAST(MAX(slr.salary) AS TEXT)\n      END AS highest_salary,\n      CASE \n          WHEN AVG(slr.salary) &gt; 1000000 THEN 'High Salary'\n          WHEN AVG(slr.salary) BETWEEN 500000 AND 1000000 THEN 'Medium Salary'\n          ELSE 'Low Salary'\n      END AS salary_category\n    FROM fielding fld\n    JOIN salaries slr \n        ON fld.playerID = slr.playerID\n    GROUP BY fld.pos\n    ORDER BY avg_salary DESC\n    LIMIT 10\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nTop-10 positions by average salary {#cell-ST1-table}\n\n\n\nposition\navg_salary\ntotal_players\nhighest_salary\nsalary_category\n\n\n\n\n0\n1B\n2800540.86\n1268\n33000000.0\nHigh Salary\n\n\n1\nOF\n2640496.41\n1796\n28000000.0\nHigh Salary\n\n\n2\nP\n2357970.04\n2872\n33000000.0\nHigh Salary\n\n\n3\n3B\n2193536.57\n1115\n33000000.0\nHigh Salary\n\n\n4\nSS\n2180598.07\n747\n33000000.0\nHigh Salary\n\n\n5\n2B\n1811115.32\n904\n26187500.0\nHigh Salary\n\n\n6\nC\n1745414.69\n482\n23000000.0\nHigh Salary",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project3.html#sq2-advanced-career-longevity-and-performance-with-subqueries",
    "href": "250_Projects/project3.html#sq2-advanced-career-longevity-and-performance-with-subqueries",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "SQ2: Advanced Career Longevity and Performance (with Subqueries)",
    "text": "SQ2: Advanced Career Longevity and Performance (with Subqueries)\nCalculate the average career length (in years) for players who have played at least one game. Then, identify the top 10 players with the longest careers (based on the number of years they played). Include their: * playerID * first_name * last_name * career_length\nThe career_length should be calculated as the difference between the maximum and minimum yearID for each player.\nAll players in the table have been playing for teams for over 25 years. The most experienced player has been playing for 36 years.\n\n\nCode - Find Top-10 players with longest carrers\nq = '''\n    SELECT \n        app.playerID,\n        ppl.nameFirst AS first_name,\n        ppl.nameLast AS last_name,\n        (MAX(app.yearID) - MIN(app.yearID) + 1) AS career_length\n    FROM appearances app\n    JOIN people ppl ON app.playerID = ppl.playerID\n    GROUP BY app.playerID\n    HAVING SUM(G_all) &gt;= 1\n    ORDER BY career_length DESC\n    LIMIT 10\n    '''\ntable = pd.read_sql_query(q,con)\ntable\n\n\n\n\n\n\nTop-10 players with longest carrers {#cell-ST2-table}\n\n\n\nplayerID\nfirst_name\nlast_name\ncareer_length\n\n\n\n\n0\naltroni01\nNick\nAltrock\n36\n\n\n1\norourji01\nJim\nO'Rourke\n33\n\n\n2\nminosmi01\nMinnie\nMinoso\n32\n\n\n3\nolearch01\nCharley\nO'Leary\n31\n\n\n4\nlathaar01\nArlie\nLatham\n30\n\n\n5\nmcguide01\nDeacon\nMcGuire\n29\n\n\n6\neversjo01\nJohnny\nEvers\n28\n\n\n7\njennihu01\nHughie\nJennings\n28\n\n\n8\nryanno01\nNolan\nRyan\n28\n\n\n9\nstreega01\nGabby\nStreet\n28\n\n\n\n\n\n\n\n\n\nClosing connection to database\ncon.close()",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "250_Projects/project2.html",
    "href": "250_Projects/project2.html",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "",
    "text": "This project helped me understand that it is always worth checking data for correctness. Despite the fact that we cannot always check how correct the data is, nevertheless, it must correspond to the type determined by the meaning of the column. Thus, if a column contains the value of the number of canceled flights, then it cannot be less than 0, and must also be a numeric value. It is important to consider all these nuances before starting to work with data. We can also take into account if the data is lost and has an empty value. Depending on the task, rows with these values may or may not be taken into account.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_flights = pd.read_json(\"https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json\")\nna_month_count = df_flights.query('month == \"n/a\"')\nlen(na_month_count)\nmissing_values_count = df_flights.isna().sum()\nmissing_values_count\n\n\nairport_code                      0\nairport_name                      0\nmonth                             0\nyear                             23\nnum_of_flights_total              0\nnum_of_delays_carrier             0\nnum_of_delays_late_aircraft       0\nnum_of_delays_nas                 0\nnum_of_delays_security            0\nnum_of_delays_weather             0\nnum_of_delays_total               0\nminutes_delayed_carrier          52\nminutes_delayed_late_aircraft     0\nminutes_delayed_nas              31\nminutes_delayed_security          0\nminutes_delayed_weather           0\nminutes_delayed_total             0\ndtype: int64",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#elevator-pitch",
    "href": "250_Projects/project2.html#elevator-pitch",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "",
    "text": "This project helped me understand that it is always worth checking data for correctness. Despite the fact that we cannot always check how correct the data is, nevertheless, it must correspond to the type determined by the meaning of the column. Thus, if a column contains the value of the number of canceled flights, then it cannot be less than 0, and must also be a numeric value. It is important to consider all these nuances before starting to work with data. We can also take into account if the data is lost and has an empty value. Depending on the task, rows with these values may or may not be taken into account.\n\n\nRead and format project data\n# Learn more about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf_flights = pd.read_json(\"https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json\")\nna_month_count = df_flights.query('month == \"n/a\"')\nlen(na_month_count)\nmissing_values_count = df_flights.isna().sum()\nmissing_values_count\n\n\nairport_code                      0\nairport_name                      0\nmonth                             0\nyear                             23\nnum_of_flights_total              0\nnum_of_delays_carrier             0\nnum_of_delays_late_aircraft       0\nnum_of_delays_nas                 0\nnum_of_delays_security            0\nnum_of_delays_weather             0\nnum_of_delays_total               0\nminutes_delayed_carrier          52\nminutes_delayed_late_aircraft     0\nminutes_delayed_nas              31\nminutes_delayed_security          0\nminutes_delayed_weather           0\nminutes_delayed_total             0\ndtype: int64",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq1-standardization-of-missing-data-types",
    "href": "250_Projects/project2.html#cq1-standardization-of-missing-data-types",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ1: Standardization of Missing Data Types",
    "text": "CQ1: Standardization of Missing Data Types\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nAfter analyzing all the columns of the table, it was discovered that: - Airport Name had empty string (’’) as value - Month had missing data (‘n/a’) - Number of Delays Carrier had missing data (‘1500+’) - Year, Minutes Delayed Carrier, Minutes Delayd Nas had missing data (‘nan’) All these values on each columns have been replaced with the value NaN. The output shows an example of the final data in json format. Here we can see that num_of_delays_carrier has a null value.\nAlso in this example we can see that value for num_of_delays_late_aircraft is -999. This seams as incorrect for a purpose of the column but in its data type it is correct.\n\n\nCode - Finding missing data (‘n/a’, ’‘, ’nan’, ‘1500+’’) and fix it with NaN value\n# Find unique data for analizing data for missing values\n# unique_values_dict = {col: df_flights[col].unique() for col in df_flights.columns}\n# Replace missing data ('n/a', '', 'nan', '1500+') with NaN\ndf_flights = df_flights.replace({'': np.nan, 'n/a': np.nan, 'nan': np.nan, '1500+': np.nan})\n# Output example JSON row\nex = df_flights[df_flights.isna().any(axis=1)].iloc[0].to_json()\nex\n\n\n'{\"airport_code\":\"ATL\",\"airport_name\":\"Atlanta, GA: Hartsfield-Jackson Atlanta International\",\"month\":\"January\",\"year\":2005.0,\"num_of_flights_total\":35048,\"num_of_delays_carrier\":null,\"num_of_delays_late_aircraft\":-999,\"num_of_delays_nas\":4598,\"num_of_delays_security\":10,\"num_of_delays_weather\":448,\"num_of_delays_total\":8355,\"minutes_delayed_carrier\":116423.0,\"minutes_delayed_late_aircraft\":104415,\"minutes_delayed_nas\":207467.0,\"minutes_delayed_security\":297,\"minutes_delayed_weather\":36931,\"minutes_delayed_total\":465533}'",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq2-analysis-of-airport-delays",
    "href": "250_Projects/project2.html#cq2-analysis-of-airport-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ2: Analysis of Airport Delays",
    "text": "CQ2: Analysis of Airport Delays\nWhich airport has the worst delays? Describe the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nIn my understanding, the worst airport is the one that has the most delayed flights, since this does not give confidence whether my flight will be canceled or not, as well as the longest delay time, because this means that I have to plan too much time, taking into account possible postponement of the flight for subsequent business. According to this definition, a table was compiled in which we can see that the SFO airport is the worst in relation to it, since it most often has delays and in fact has the longest average delay time.\n\n\nCode - Analysis of Airport Delays\n# Add the average delay time in hours column\nworst_delays = df_flights.assign(hours_delayed_total = df_flights.minutes_delayed_total/df_flights.num_of_delays_total/60)\n# Group rows by the 'airport code'\nworst_delays = worst_delays.groupby(\"airport_code\").agg(\n    total_flights = ('num_of_flights_total', 'sum'),\n    total_delays = ('num_of_delays_total', 'sum'),\n    avg_delay_hours = ('hours_delayed_total', 'mean')\n)\n# Add the proportion of delayed flights column\nworst_delays['proportion_of_delayed'] = worst_delays['total_delays'] / worst_delays['total_flights']\n# Sort table by the average delay time in hours and proportion of delayed flights\nworst_delays = worst_delays.sort_values(['proportion_of_delayed', 'avg_delay_hours'], ascending=False)\n# Print out table\ndisplay(worst_delays)\n\n\n\n\n\n\nRating of airports {#cell-CQ2-table}\n\n\n\ntotal_flights\ntotal_delays\navg_delay_hours\nproportion_of_delayed\n\n\nairport_code\n\n\n\n\n\n\n\n\nSFO\n1630945\n425604\n1.017653\n0.260955\n\n\nORD\n3597588\n830825\n1.105717\n0.230939\n\n\nATL\n4430047\n902443\n0.989502\n0.203710\n\n\nIAD\n851571\n168467\n1.003245\n0.197831\n\n\nSAN\n917862\n175132\n0.784028\n0.190804\n\n\nDEN\n2513974\n468519\n0.882581\n0.186366\n\n\nSLC\n1403384\n205160\n0.823587\n0.146189",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq3-optimal-month-for-minimizing-flight-delays",
    "href": "250_Projects/project2.html#cq3-optimal-month-for-minimizing-flight-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ3: Optimal Month for Minimizing Flight Delays",
    "text": "CQ3: Optimal Month for Minimizing Flight Delays\nWhat is the best month to fly if you want to avoid delays of any length? Describe the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nIn this graph we can see the percentage of delayed flights for each month. So we see that December has the most flight delays, so there’s a good chance our flight will be delayed this month too. While in September, according to statistics, the least flight delays occur. Therefore, if you are planning a trip by plane, then the best month for your plans to best match your expectations is September.\n\n\nCode - Analyse data for each month for minimizing flight delays\n# clear wrong data (February)\ndf_flights.replace('Febuary', 'February', inplace=True)\n# Delete all rows with no named month\nd_months = df_flights.query(\"@pd.notnull(month)\")\n# Group rows by month\nd_months = d_months.groupby('month').agg(\n    total_flights = ('num_of_flights_total', 'sum'),\n    total_delays = ('num_of_delays_total', 'sum')\n).reset_index()\n# Add the proportion of delayed flights in % column\nd_months['proportion_of_delayed'] = round(d_months['total_delays'] / d_months['total_flights'], 2)*100\n# Sort table by the 'months'\nmonth_dict = {'January':1,'February':2,'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\nd_months = d_months.sort_values(['month'], key = lambda x : x.apply (lambda x : month_dict[x]), ascending=True).reset_index(drop=True)\n\n# Identify best and worst months\nbest_month = d_months.loc[d_months['proportion_of_delayed'].idxmin(), 'month']\nworst_month = d_months.loc[d_months['proportion_of_delayed'].idxmax(), 'month']\n\nd_months['color'] = np.where(d_months['month'] == best_month, 'blue', \n                             np.where(d_months['month'] == worst_month, 'red', 'gray'))\n\n# Draw chart\nchart = ggplot(d_months, aes(x='month', y='proportion_of_delayed', fill='color')) + \\\n    geom_bar(stat='identity') + \\\n      scale_fill_identity() + \\\n    ggtitle('Proportion of Delayed Flights by Month') + \\\n    xlab('Month') + \\\n    ylab('Proportion of Delayed Flights')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nChart shows The proportion of delays for each month and indicate best and worst of it",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq4-calculation-of-total-weather-related-flight-delays",
    "href": "250_Projects/project2.html#cq4-calculation-of-total-weather-related-flight-delays",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ4: Calculation of Total Weather-Related Flight Delays",
    "text": "CQ4: Calculation of Total Weather-Related Flight Delays\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\na. 100% of delayed flights in the Weather category are due to weather b. 30% of all delayed flights in the Late-Arriving category are due to weather c. From April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%\nWhile studying the data necessary for the calculations, it was discovered that flights delayed due to a late plane had incorrect data in the form of -999, which I corrected to the average value for this column. The remaining columns required for calculations had data correct for calculations.\n\n\nCode - Calculation of Total Weather-Related Flight Delays\n# Fill missing data\n# Use mean value for missing data\nmean_late_aircraft = df_flights.num_of_delays_late_aircraft.mean()\ndf_flights.replace(-999, mean_late_aircraft, inplace=True)\ndf_flights.fillna(mean_late_aircraft, inplace=True)\n# calculate delays by weather\npredata = df_flights.assign(delays_by_weather_months = lambda x: 0.4*x.num_of_delays_nas if str(x.month) in ['April', 'May', 'June', 'July', 'August'] else 0.65*x.num_of_delays_nas)\npredata = predata.assign(delays_by_weather = lambda x: x.num_of_delays_weather + 0.3*x.num_of_delays_late_aircraft + x.delays_by_weather_months)\n\n# Columns to include in the resut table\ncolumns_to_include = ['airport_code', 'airport_name', 'month', 'num_of_flights_total', 'num_of_delays_total', 'num_of_delays_weather', 'num_of_delays_late_aircraft', 'num_of_delays_nas', 'delays_by_weather']\n# Filter DataFrame to include only desired columns\ndata4 = predata[columns_to_include]\ntable4 = data4.head(5)\n\ntable4\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nnum_of_flights_total\nnum_of_delays_total\nnum_of_delays_weather\nnum_of_delays_late_aircraft\nnum_of_delays_nas\ndelays_by_weather\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n35048\n8355\n448\n1017.844156\n4598\n3742.053247\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n12687\n3153\n233\n928.000000\n935\n1119.150000\n\n\n2\nIAD\n1017.844156\nJanuary\n12381\n2430\n61\n1058.000000\n895\n960.150000\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n28194\n9178\n306\n2255.000000\n5415\n4502.250000\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n7283\n1952\n56\n680.000000\n638\n674.700000",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#cq5-analysis-of-weather-related-flight-delays-by-airport",
    "href": "250_Projects/project2.html#cq5-analysis-of-weather-related-flight-delays-by-airport",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "CQ5: Analysis of Weather-Related Flight Delays by Airport",
    "text": "CQ5: Analysis of Weather-Related Flight Delays by Airport\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Describe what you learn from this graph.\nAccording to statistics and taking into account all data errors on the histogram, we can see the following: Siberian Federal District, ORD, ATL have approximately the same high percentage of flights delayed due to weather - 40+%. This means that when choosing these airports, you should pay attention to the expected weather when flying in that region. SAN Airport has the lowest percentage of flights delayed due to weather - 30%.\n\n\nCode - Filter data of Weather-Related Flight Delays by Airport\ndata5 = predata.groupby(\"airport_code\").agg(\n    total_num_of_delays = ('num_of_delays_total', 'sum'),\n    num_of_delays_weather = ('num_of_delays_weather', 'sum'),\n    numu_of_delays_late_aircraft = ('num_of_delays_late_aircraft', 'sum'),\n    num_of_delays_nas = ('num_of_delays_nas', 'sum'),\n    total_num_of_delays_by_weather = ('delays_by_weather', 'sum')\n).reset_index()\n# Add the 'proportion of delayed flights by weather' column\ndata5 = data5.assign(proportion_of_delayed_flights_by_weather = lambda x: round(x.total_num_of_delays_by_weather/x.total_num_of_delays, 2)*100)\n\nchart = ggplot(data5, aes(x='airport_code', y='proportion_of_delayed_flights_by_weather')) + \\\n    geom_bar(stat='identity') + \\\n    ggtitle('Proportion of Delayed Flights by Month') + \\\n    xlab('Airport code') + \\\n    ylab('Rate of delayed flights by weather in %')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing Weather-Related Flight Delays by Airport",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "250_Projects/project2.html#sq1-comparative-analysis-of-flight-delay-types",
    "href": "250_Projects/project2.html#sq1-comparative-analysis-of-flight-delay-types",
    "title": "Client Report - Late Flights & Missing Data (JSON)",
    "section": "SQ1: Comparative Analysis of Flight Delay Types",
    "text": "SQ1: Comparative Analysis of Flight Delay Types\nWhich delay is the worst delay? Create a similar analysis as above for Weahter Delay with: Carrier Delay and Security Delay. Compare the proportion of delay for each of the three categories in a Chart and a Table. Describe your results.\nWhen examining the data needed for the calculations, it was discovered that the required columns had incorrect data, which I corrected to the average of that column. According to statistics and taking into account all the data errors on the histogram, we see the following: the largest number of delays is associated with weather - 39%, the smallest number of delays is associated with security - almost 0%.\n\n\nCode - Filter data for Comparison of Delay Percentage by Delay Type\n# Clear num_of_delays_carrier\npredata['Numeric_Column'] = pd.to_numeric(predata['num_of_delays_carrier'], errors='coerce')\nmean_value = predata['Numeric_Column'].mean()\npredata['num_of_delays_carrier'] = predata['Numeric_Column'].fillna(mean_value)\n# Clear num_of_delays_security\npredata['Numeric_Column'] = pd.to_numeric(predata['num_of_delays_security'], errors='coerce')\nmean_value = predata['Numeric_Column'].mean()\npredata['num_of_delays_security'] = predata['Numeric_Column'].fillna(mean_value)\n\npredata['Numeric_Column'] = 1\ndata6 = predata.groupby(\"Numeric_Column\").agg(\n    total_num_of_delays = ('num_of_delays_total', 'sum'),\n    num_of_delays_weather = ('num_of_delays_weather', 'sum'),\n    numu_of_delays_late_aircraft = ('num_of_delays_late_aircraft', 'sum'),\n    num_of_delays_nas = ('num_of_delays_nas', 'sum'),\n    total_num_of_delays_by_weather = ('delays_by_weather', 'sum'),\n    num_of_delays_carrier = ('num_of_delays_carrier', 'sum'),\n    num_of_delays_security = ('num_of_delays_security', 'sum')\n).reset_index()\n# Add the 'proportion of delayed flights by weather' column\ndata6 = data6.assign(rate_of_delayed_flights_by_weather = lambda x: round(x.total_num_of_delays_by_weather/x.total_num_of_delays, 2)*100)\ndata6 = data6.assign(rate_of_delayed_flights_by_carrier = lambda x: round(x.num_of_delays_carrier/x.total_num_of_delays, 2)*100)\ndata6 = data6.assign(rate_of_delayed_flights_by_security = lambda x: round(x.num_of_delays_security/x.total_num_of_delays, 2)*100)\n# Columns to include in the resut table\ncolumns_to_include = ['rate_of_delayed_flights_by_weather', 'rate_of_delayed_flights_by_carrier', 'rate_of_delayed_flights_by_security']\n# Filter DataFrame to include only desired columns\ndata = data6[columns_to_include]\ndata\n\n\n\n\n\n\n\n\n\nrate_of_delayed_flights_by_weather\nrate_of_delayed_flights_by_carrier\nrate_of_delayed_flights_by_security\n\n\n\n\n0\n39.0\n21.0\n0.0\n\n\n\n\n\n\n\n\n\nCode - Creating graph for Comparison of Delay Percentage by Delay Type\ndelay_comparison = data6[['Numeric_Column', 'rate_of_delayed_flights_by_carrier', 'rate_of_delayed_flights_by_security', 'rate_of_delayed_flights_by_weather']]\n\ndelay_comparison_melted = delay_comparison.melt(id_vars='Numeric_Column', \n                                                var_name='Delay_Type', \n                                                value_name='Delay_Percentage')\n\n# График с пропорциями задержек по типам\nchart = ggplot(delay_comparison_melted, aes(x='Delay_Type', y='Delay_Percentage', fill='Delay_Type')) + \\\n    geom_bar(stat='identity', position='dodge') + \\\n    ggtitle('Comparison of Delay Types by Delay Type') + \\\n    xlab('Delay_Type') + \\\n    ylab('Percentage of Delays') + \\\n    scale_fill_brewer(type='qual', palette='Set1')\n\nchart\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nA chart showing the dependence of delay persentage by delay type",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Physicist, Mathematician, Cambridge professor.\n\nisaac@applesdofall.org | My wikipedia page\n\n\n\nStanding on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples.\n\n\n\n\n1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow\n\n\n\n\n2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France\n\n\n\n\n\n\n1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001\n\n\n\n\n1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "250_projects.html",
    "href": "250_projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0 - Introduction\nProject 1 - What’s in a Name\nProject 2 - Late Flights and Missing Data (JSON)\nProject 3 - Finding Relationships in Baseball\nProject 4 - Can you Predict That?\nProject 5 - The War with StarWars\nProject 6 - Git Your Portfolio Online",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "250_projects.html#repo-for-all-my-projects",
    "href": "250_projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0 - Introduction\nProject 1 - What’s in a Name\nProject 2 - Late Flights and Missing Data (JSON)\nProject 3 - Finding Relationships in Baseball\nProject 4 - Can you Predict That?\nProject 5 - The War with StarWars\nProject 6 - Git Your Portfolio Online",
    "crumbs": [
      "DS250 Projects"
    ]
  }
]